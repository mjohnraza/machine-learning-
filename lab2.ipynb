{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547f4f76",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "source": [
    "## Task 1: Dataset Combination\n",
    "\n",
    "### B. Combine Lab2 D1A with Lab2 D1B without duplicate columns\n",
    "### C. Combine Lab2 D1A with Lab2 D1C using merge method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6222d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1A shape: (26983, 5)\n",
      "D1A columns: ['fid', 'name', 'population', 'county', 'latitude']\n",
      "---\n",
      "D1B shape: (26983, 7)\n",
      "D1B columns: ['name', 'population', 'county', 'longitude', 'level1', 'enrollment', 'level2']\n",
      "---\n",
      "D1C shape: (26983, 3)\n",
      "D1C columns: ['county', 'city', 'score']\n",
      "\n",
      "--- Task 1B: Combined D1A and D1B ---\n",
      "Combined shape: (27033, 9)\n",
      "Combined columns: ['fid', 'name', 'population', 'county', 'latitude', 'longitude', 'level1', 'enrollment', 'level2']\n",
      "\n",
      "--- Task 1C: Combined D1A and D1C ---\n",
      "ComboAC shape: (26983, 7)\n",
      "ComboAC columns: ['fid', 'name', 'population', 'county', 'latitude', 'city', 'score']\n",
      "Expected records (should be same as D1A): 26983 , got: 26983\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "d1a = pd.read_csv(\"Lab2 D1A.csv\")\n",
    "d1b = pd.read_csv(\"Lab2 D1B.csv\", header=0, names=[\"name\", \"population\", \"county\", \"longitude\", \"level1\", \"enrollment\", \"level2\"])\n",
    "d1c = pd.read_csv(\"Lab2 D1C.csv\")\n",
    "\n",
    "# Display info about datasets\n",
    "print(\"D1A shape:\", d1a.shape)\n",
    "print(\"D1A columns:\", d1a.columns.tolist())\n",
    "print(\"---\")\n",
    "print(\"D1B shape:\", d1b.shape)\n",
    "print(\"D1B columns:\", d1b.columns.tolist())\n",
    "print(\"---\")\n",
    "print(\"D1C shape:\", d1c.shape)\n",
    "print(\"D1C columns:\", d1c.columns.tolist())\n",
    "\n",
    "# Task 1B: Combine datasets without duplicate columns\n",
    "# We'll merge on the common columns to ensure data is aligned correctly.\n",
    "# The common columns are 'name', 'population', and 'county'.\n",
    "combined_df = pd.merge(d1a, d1b, on=['name', 'population', 'county'])\n",
    "\n",
    "# Display info about combined dataset\n",
    "print(\"\\n--- Task 1B: Combined D1A and D1B ---\")\n",
    "print(\"Combined shape:\", combined_df.shape)\n",
    "print(\"Combined columns:\", combined_df.columns.tolist())\n",
    "\n",
    "\n",
    "# Task 1C: Combine D1A with D1C using merge method\n",
    "# We will use a 'left' merge to keep all rows from D1A and add matching data from D1C.\n",
    "# To avoid the Cartesian product, we'll drop duplicates from D1C before merging.\n",
    "d1c_unique = d1c.drop_duplicates(subset=['county'])\n",
    "comboAC = pd.merge(d1a, d1c_unique, on='county', how='left')\n",
    "\n",
    "\n",
    "# Display info about merged dataset\n",
    "print(\"\\n--- Task 1C: Combined D1A and D1C ---\")\n",
    "print(\"ComboAC shape:\", comboAC.shape)\n",
    "print(\"ComboAC columns:\", comboAC.columns.tolist())\n",
    "print(\"Expected records (should be same as D1A):\", d1a.shape[0], \", got:\", comboAC.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130669cd",
   "metadata": {},
   "source": [
    "## Task 2: Custom Dataset Creation and Merging\n",
    "\n",
    "### A. Create customizedData dataset with specified attributes\n",
    "### B. Merge customizedData with Lab2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa46f273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomizedData shape: (1000, 10)\n",
      "CustomizedData columns: ['fid', 'name', 'population', 'county', 'latitude', 'size', 'cardinal_direction', 'timings', 'school_type', 'funding']\n",
      "\n",
      "--- Merging Datasets ---\n",
      "\n",
      "ModifiedData shape after merging: (1000, 16)\n",
      "ModifiedData columns: ['fid', 'name', 'population', 'county', 'latitude', 'size', 'cardinal_direction', 'timings', 'school_type', 'funding', 'longitude', 'level1', 'enrollment', 'level2', 'city', 'score']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Assume d1a, d1b, and d1c are already loaded from the previous step\n",
    "# d1a = pd.read_csv(\"Lab2 D1A.csv\")\n",
    "# d1b = pd.read_csv(\"Lab2 D1B.csv\", header=0, names=[\"name\", \"population\", \"county\", \"longitude\", \"level1\", \"enrollment\", \"level2\"])\n",
    "# d1c = pd.read_csv(\"Lab2 D1C.csv\")\n",
    "\n",
    "# Take a sample of records to create our custom dataset\n",
    "sample_size = 1000\n",
    "custom_data = d1a.sample(n=sample_size, random_state=42).copy()\n",
    "\n",
    "# Add Size attribute (categorical: small, medium, high)\n",
    "sizes = ['small', 'medium', 'high']\n",
    "custom_data['size'] = [random.choice(sizes) for _ in range(sample_size)]\n",
    "\n",
    "# Add cardinal direction attribute (categorical: North, South, East, West)\n",
    "directions = ['North', 'South', 'East', 'West']\n",
    "custom_data['cardinal_direction'] = [random.choice(directions) for _ in range(sample_size)]\n",
    "\n",
    "# Add Timings attribute (categorical: full time, part time)\n",
    "timings = ['full time', 'part time']\n",
    "custom_data['timings'] = [random.choice(timings) for _ in range(sample_size)]\n",
    "\n",
    "# Add one categorical attribute of my own choice (school type)\n",
    "school_types = ['public', 'private', 'charter']\n",
    "custom_data['school_type'] = [random.choice(school_types) for _ in range(sample_size)]\n",
    "\n",
    "# Add one continuous attribute of my own choice (funding in thousands of dollars)\n",
    "custom_data['funding'] = np.random.normal(500, 150, sample_size)  # Mean 500k, std 150k\n",
    "custom_data['funding'] = custom_data['funding'].abs()  # Ensure positive values\n",
    "\n",
    "# Display info about custom dataset\n",
    "print(\"CustomizedData shape:\", custom_data.shape)\n",
    "print(\"CustomizedData columns:\", custom_data.columns.tolist())\n",
    "\n",
    "# Task 2B: Merge customizedData with Lab2 datasets\n",
    "print(\"\\n--- Merging Datasets ---\")\n",
    "\n",
    "# Merge the custom data with D1B on common keys\n",
    "modifiedData = pd.merge(custom_data, d1b, on=['name', 'population', 'county'], how='left')\n",
    "\n",
    "# De-duplicate D1C to prepare for a clean merge\n",
    "d1c_unique = d1c.drop_duplicates(subset=['county'])\n",
    "\n",
    "# Merge the result with the de-duplicated D1C on the 'county' key\n",
    "modifiedData = pd.merge(modifiedData, d1c_unique, on='county', how='left')\n",
    "\n",
    "print(\"\\nModifiedData shape after merging:\", modifiedData.shape)\n",
    "print(\"ModifiedData columns:\", modifiedData.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
